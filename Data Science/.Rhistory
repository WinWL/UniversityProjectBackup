## 13 Variables
df.raw.final <- subset(df.rNA, select = c(Class,
Odor, StalkColorBelowRing,
Population, StalkColorAboveRing,
StalkSurfaceBelowRing, GillSize, GillColor,
RingColor, Bruises, StalkRoot,
StalkSurfaceAboveRing, CapColor, StalkShape)) %>% as.data.frame()
df.raw.arul <- subset(df.rNA, select = -c(Odor, StalkColorBelowRing,
Population, StalkColorAboveRing,
StalkSurfaceBelowRing, GillSize, GillColor,
RingColor, Bruises, StalkRoot,
StalkSurfaceAboveRing, CapColor, StalkShape)) %>% as.data.frame()
params <- list(support=0.055,confidence=0.8,minlen=2,maxlen=4)
out.aRul <- predArules(df.raw.arul, fmin = 2, fmax = 4)
# Getting ARI for all methods
set.seed(102032)
test.AllARI5 <-
foreach(
index = 1:30, # Loops over the choice of alleles
.combine = rbind,
.multicombine = TRUE,
.packages = c("dplyr", "randomForest", "e1071",
"mclust", "tree", "nnet", "gbm")
) %dopar% {
df.raw.forA <- df.raw.final
df.raw.forA.num <- data.matrix(df.raw.forA)
# Training set
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
out.All <- predAll(df.raw.forA, df.train.index, df.raw.forA.num, DoBagMethod = F, fMtry = 4)
out.A.Ari <- setNames(
list(out.All$TreeAri, out.All$ForestAri,
out.All$BagAri, out.All$BoostAri,
out.All$MclustAri, out.All$NnetAri),
c("Tree", "Forest", "Bag", "Boost", "Mclust", "Nnet"))
out.df.row <- out.A.Ari %>% t %>% data.frame()
rownames(out.df.row) <- paste("ARI", index, sep = "")
return(out.df.row)
} %>% apply(1, function(x) unlist(x)) %>% t
test.AllARI5.withv <- cbind(test.AllARI5, rep(13, nrow(test.AllARI5)))
## 16 Variables
df.raw.final <- subset(df.rNA, select = c(Class,
Odor, StalkColorBelowRing,
Population, StalkColorAboveRing,
StalkSurfaceBelowRing, GillSize, GillColor,
RingColor, Bruises, StalkRoot,
StalkSurfaceAboveRing, CapColor, StalkShape,
SporePrintColor, GillSpacing, Habitat)) %>% as.data.frame()
df.raw.arul <- subset(df.rNA, select = -c(Odor, StalkColorBelowRing,
Population, StalkColorAboveRing,
StalkSurfaceBelowRing, GillSize, GillColor,
RingColor, Bruises, StalkRoot,
StalkSurfaceAboveRing, CapColor, StalkShape,
SporePrintColor, GillSpacing, Habitat)) %>% as.data.frame()
params <- list(support=0.055,confidence=0.8,minlen=2,maxlen=4)
out.aRul <- predArules(df.raw.arul, fmin = 2, fmax = 4)
# Getting ARI for all methods
set.seed(102032)
# Getting ARI for all methods
set.seed(102032)
test.AllARI6 <-
foreach(
index = 1:30, # Loops over the choice of alleles
.combine = rbind,
.multicombine = TRUE,
.packages = c("dplyr", "randomForest", "e1071",
"mclust", "tree", "nnet", "gbm")
) %dopar% {
df.raw.forA <- df.raw.final %>% as.data.frame()
df.raw.forA.num <- data.matrix(df.raw.forA)
# Training set
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
out.All <- predAll(df.raw.forA, df.train.index, df.raw.forA.num, DoBagMethod = F, fMtry = 4)
out.A.Ari <- setNames(
list(out.All$TreeAri, out.All$ForestAri,
out.All$BagAri, out.All$BoostAri,
out.All$MclustAri, out.All$NnetAri),
c("Tree", "Forest", "Bag", "Boost", "Mclust", "Nnet"))
out.df.row <- out.A.Ari %>% t %>% data.frame()
rownames(out.df.row) <- paste("ARI", index, sep = "")
return(out.df.row)
} %>% apply(1, function(x) unlist(x)) %>% t
test.AllARI6.withv <- cbind(test.AllARI6, rep(16, nrow(test.AllARI6)))
AriVarTest <- (rbind(
test.AllARI1.withv,
test.AllARI2.withv,
test.AllARI3.withv,
test.AllARI4.withv,
test.AllARI5.withv,
test.AllARI6.withv)) %>% as.data.frame()
colnames(AriVarTest) <- c("Forest", "Nnet", "VariablesUsed")
rownames(AriVarTest) <- c(1:nrow(AriVarTest))
AriVarTest
dfCleanAri <- melt(AriVarTest, "VariablesUsed")
colnames(dfCleanAri) <- c("VariablesUsed", "Method", "ARI")
dfCleanAri$VariablesUsed <- dfCleanAri$VariablesUsed %>% as.factor()
dfPlot <- dfCleanAri
# 2 data points removed so box plot is more readable
dfPlot %>% filter(ARI <= 0.85)
dfPlotBox <- dfPlot %>% filter(ARI > 0.85)
ggplot(dfPlotBox, aes(x=VariablesUsed, y=ARI, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("Comparing ARI Performance of Neutral Nets and Random Forests")
## 13 Variables
df.raw.final <- subset(df.rNA, select = c(Class,
Odor, StalkColorBelowRing,
Population, StalkColorAboveRing,
StalkSurfaceBelowRing, GillSize, GillColor,
RingColor, Bruises, StalkRoot,
StalkSurfaceAboveRing, CapColor, StalkShape)) %>% as.data.frame()
mTryChoice <- seq(1, 13, by=1)
nTreeChoice <- seq(300, 600, by=50)
mTryTreeComboMat <- expand.grid(mTryChoice,nTreeChoice)
colnames(mTryTreeComboMat) <- c("mTry", "nTree")
mTryTreeComboMat
# index <- 1
cores = detectCores()
cl <- makeCluster(cores[1] - 1) #not to overload your computer. Leaves for regular use
registerDoParallel(cl)
set.seed(102032)
opt.ForestParam <-
foreach(
index = 1:nrow(mTryTreeComboMat), # Loops over the choice of alleles
.combine = rbind,
.multicombine = TRUE,
.packages = c("dplyr", "randomForest", "e1071",
"mclust", "tree", "nnet", "gbm")
) %dopar% {
cmTry <- mTryTreeComboMat[index,1]
cnTree <- mTryTreeComboMat[index,2]
ariVec <- sapply(c(1:25), function(x) {
df.raw.forA <- df.raw.final %>% as.data.frame()
# Training set
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
out.All <- predForest(df.Final = df.raw.forA, df.Index.Train = df.train.index, fMtry = cmTry, fnTree = cnTree)
return(out.All$ForestAri)
})
out.df.row <- c(mean(ariVec), cmTry, cnTree)
return(out.df.row)
}
colnames(opt.ForestParam) <- c("AverageARI", "mTry", "nTree")
stopCluster(cl)
df.opt.For <- opt.ForestParam %>% as.data.frame()
df.opt.For.o <- df.opt.For[order(df.opt.For$AverageARI, decreasing = T),]
df.opt.For.o
df.opt.For.o.print <- rbind(df.opt.For.o[1:5,], df.opt.For.o[(nrow(opt.ForestParam) - 4):nrow(opt.ForestParam),])
df.opt.For.o.print
print(
xtable(  df.opt.For.o.print, type = "latex", digits = c(1,4,0,0)),
file = "ttForParam.txt",
include.rownames=F
)
ggplot(df.opt.For.o, aes(x = mTry, y = nTree, fill = AverageARI)) +
geom_point(size=2, shape=23)
df.opt.For.o.print
#############
# Neural Net Optimization for 13 VARIABLES
df.raw.final <- subset(df.rNA, select = c(Class,
Odor, StalkColorBelowRing,
Population, StalkColorAboveRing,
StalkSurfaceBelowRing, GillSize, GillColor,
RingColor, Bruises, StalkRoot,
StalkSurfaceAboveRing, CapColor, StalkShape)) %>% as.data.frame()
fSizeChoice <- seq(2, 7, by=1)
fMaxitChoice <- seq(100, 500, by=100)
fDecayChoice <- seq(0, 0.5, by=0.25)
mPComboNnetMat <- expand.grid(fSizeChoice,fMaxitChoice, fDecayChoice)
colnames(mPComboNnetMat) <- c("fSize", "fMaxit", "fDecay")
mPComboNnetMat
cores = detectCores()
cl <- makeCluster(cores[1] - 1) #not to overload your computer. Leaves for regular use
registerDoParallel(cl)
set.seed(102032)
opt.NnetParam <-
foreach(
index = 1:nrow(mPComboNnetMat), # Loops over the choice of parameters
.combine = rbind,
.multicombine = TRUE,
.packages = c("dplyr", "randomForest", "e1071",
"mclust", "tree", "nnet", "gbm")
) %dopar% {
cmSize <- mPComboNnetMat[index,1]
cnMax <- mPComboNnetMat[index,2]
cnDecay <- mPComboNnetMat[index,3]
# Average of 25 ARI's
ariVec <- sapply(c(1:25), function(x) {
df.raw.forA <- df.raw.final %>% as.data.frame()
# Training set
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
out.All <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = cmSize, fMaxit = cnMax, fDecay = cnDecay )
return(out.All$NnetAri)
})
out.df.row <- c(mean(ariVec), cmSize, cnMax, cnDecay)
return(out.df.row)
}
stopCluster(cl)
colnames(opt.NnetParam) <- c("AverageARI", "Size", "Maxit", "Decay")
df.opt.Nnet <- opt.NnetParam %>% as.data.frame()
df.opt.Nnet.o <- df.opt.Nnet[order(df.opt.Nnet$AverageARI, decreasing = T),]
df.opt.Nnet.o
df.opt.Nnet.o.print <- rbind(df.opt.Nnet.o[1:5,], df.opt.Nnet.o[(nrow(opt.NnetParam) - 4):nrow(opt.NnetParam),])
df.opt.Nnet.o.print
print(
xtable(  df.opt.Nnet.o.print, type = "latex", digits = c(1,4,0,0,2)),
file = "ttNnetParam.txt",
include.rownames=F
)
df.raw.final <- subset(df.rNA, select = c(Class,
Odor, StalkColorBelowRing,
Population, StalkColorAboveRing,
StalkSurfaceBelowRing, GillSize, GillColor,
RingColor, Bruises, StalkRoot,
StalkSurfaceAboveRing, CapColor, StalkShape)) %>% as.data.frame()
df.raw.forA <- df.raw.final
set.seed(102031)
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
opt.pred.net <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = 7, fMaxit = 500, fDecay = 0 )
opt.pred.for <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
opt.pred.net
opt.pred.for$ForestTab
opt.pred.net$NnetTab
opt.pred.net$NnetAri
opt.pred.for$ForestAri
opt.pred.for$ForestMod
opt.pred.net$NnetMod
opt.pred.net$NnetAri
opt.pred.for$ForestAri
opt.pred.for$ForestTab
opt.pred.net$NnetTab
set.seed(102034)
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
opt.pred.net <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = 7, fMaxit = 500, fDecay = 0 )
opt.pred.for <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
opt.pred.net$NnetAri
opt.pred.for$ForestAri
opt.pred.for$ForestTab
opt.pred.net$NnetTab
apply(c(1:3), function(x) {
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
opt.pred.net <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = 7, fMaxit = 500, fDecay = 0 )
opt.pred.for <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
opt.pred.net$NnetAri
opt.pred.for$ForestAri
opt.pred.for$ForestTab
opt.pred.net$NnetTab
c(opt.pred.net$NnetAri, opt.pred.for$ForestAri)
})
apply(c(1:3), 2, function(x) {
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
opt.pred.net <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = 7, fMaxit = 500, fDecay = 0 )
opt.pred.for <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
opt.pred.net$NnetAri
opt.pred.for$ForestAri
opt.pred.for$ForestTab
opt.pred.net$NnetTab
c(opt.pred.net$NnetAri, opt.pred.for$ForestAri)
})
apply(diag(3), 2, function(x) {
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
opt.pred.net <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = 7, fMaxit = 500, fDecay = 0 )
opt.pred.for <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
opt.pred.net$NnetAri
opt.pred.for$ForestAri
opt.pred.for$ForestTab
opt.pred.net$NnetTab
c(opt.pred.net$NnetAri, opt.pred.for$ForestAri)
})
apply(diag(4), 2, function(x) {
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
opt.pred.net <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = 7, fMaxit = 500, fDecay = 0 )
opt.pred.for <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
# opt.pred.net$NnetAri
# opt.pred.for$ForestAri
A <- opt.pred.for$ForestTab
B <- opt.pred.net$NnetTab
# sum(A[row(A)!=col(A)])
#
# opt.pred.for$ForestTab
# opt.pred.net$NnetTab
c(opt.pred.net$NnetAri, opt.pred.for$ForestAri, sum(A[row(A)!=col(A)]), sum(B[row(B)!=col(B)]))
})
apply(diag(4), 2, function(x) {
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
opt.pred.net <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = 7, fMaxit = 500, fDecay = 0 )
opt.pred.for <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
# opt.pred.net$NnetAri
# opt.pred.for$ForestAri
A <- opt.pred.for$ForestTab
B <- opt.pred.net$NnetTab
# sum(A[row(A)!=col(A)])
#
# opt.pred.for$ForestTab
# opt.pred.net$NnetTab
c(opt.pred.net$NnetAri, opt.pred.for$ForestAri, sum(A[row(A)!=col(A)]), sum(B[row(B)!=col(B)]))
})
set.seed(102034)
apply(diag(4), 2, function(x) {
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
opt.pred.net <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = 7, fMaxit = 500, fDecay = 0 )
opt.pred.for <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
# opt.pred.net$NnetAri
# opt.pred.for$ForestAri
A <- opt.pred.for$ForestTab
B <- opt.pred.net$NnetTab
# sum(A[row(A)!=col(A)])
#
# opt.pred.for$ForestTab
# opt.pred.net$NnetTab
c(opt.pred.net$NnetAri, opt.pred.for$ForestAri, sum(A[row(A)!=col(A)]), sum(B[row(B)!=col(B)]))
}) %>% t
set.seed(102034)
sum.opt <- apply(diag(25), 2, function(x) {
df.train.index <- sample(
1:length(df.raw.forA$Class), 0.50*length(df.raw.forA$Class))
opt.pred.net <- predNnet(df.Final = df.raw.forA, df.Index.Train = df.train.index,
fSize = 7, fMaxit = 500, fDecay = 0 )
opt.pred.for <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
# opt.pred.net$NnetAri
# opt.pred.for$ForestAri
A <- opt.pred.for$ForestTab
B <- opt.pred.net$NnetTab
# sum(A[row(A)!=col(A)])
#
# opt.pred.for$ForestTab
# opt.pred.net$NnetTab
c(opt.pred.net$NnetAri, opt.pred.for$ForestAri, sum(A[row(A)!=col(A)]), sum(B[row(B)!=col(B)]))
}) %>% t
sum.opt
colnames(sum.opt) <- c("NnetARI", "ForestARI", "NnetMisclassifications", "ForestMisclassification")
sum.opt
sun.opt.plot <- melt(sum.opt, id.vars = c("NnetMisclassifications", "ForestMisclassification"))
sun.opt.plot
?melt
?melt
sun.opt.plot <- melt(sum.opt, id.vars = c("NnetMisclassifications", "ForestMisclassification"), measure.vars = c("NnetARI, ForestARI"))
sun.opt.plot
sun.opt.plot <- melt(sum.opt, id.vars = c("NnetMisclassifications"), measure.vars = c("NnetARI, ForestARI"))
sun.opt.plot
sun.opt.plot <- melt(sum.opt, "NnetMisclassifications")
sun.opt.plot
sum.opt
sun.opt.plot <- melt(sum.opt[,c(1,2)])
sun.opt.plot
colnames(sum.opt) <- c("Nnet", "Forest", "NnetM", "ForestM")
sun.opt.plot <- melt(sum.opt[,c(1,2)])
colname(sun.opt.plot) <- c("rm", "Method", "ARI")
dfPlotBox <- sun.opt.plot
ggplot(dfPlotBox, aes(x=Method, y=ARI, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("Comparing ARI Performance of Optimized Neutral Nets and Random Forests")
sun.opt.plot
colnames(sun.opt.plot) <- c("rm", "Method", "ARI")
sun.opt.plot
dfPlotBox <- sun.opt.plot
ggplot(dfPlotBox, aes(x=Method, y=ARI, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("Comparing ARI Performance of Optimized Neutral Nets and Random Forests")
# Misclassification Number Plot
colnames(sum.opt) <- c("NnetM", "ForestM", "Nnet", "Forest")
sun.opt.plot.mis <- melt(sum.opt[,-c(1,2)])
colnames(sun.opt.plot.mis) <- c("rm", "Method", "ARI")
ggplot(sun.opt.plot.mis, aes(x=Method, y=ARI, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("Misclassification Number of Optimized Neutral Nets and Random Forests")
sun.opt.plot.ari
ggplot(sun.opt.plot.ari, aes(x=Method, y=ARI, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("ARI of Optimized Neutral Nets and Random Forests")+
theme(legend.position="none")
# ARI Plot
colnames(sum.opt) <- c("Nnet", "Forest", "NnetM", "ForestM")
sun.opt.plot.ari <- melt(sum.opt[,c(1,2)])
colnames(sun.opt.plot.ari) <- c("rm", "Method", "ARI")
sun.opt.plot.ari
ggplot(sun.opt.plot.ari, aes(x=Method, y=ARI, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("ARI of Optimized Neutral Nets and Random Forests")+
theme(legend.position="none")
# Misclassification Number Plot
colnames(sum.opt) <- c("NnetM", "ForestM", "Nnet", "Forest")
sun.opt.plot.mis <- melt(sum.opt[,-c(1,2)])
colnames(sun.opt.plot.mis) <- c("rm", "Method", "ARI")
ggplot(sun.opt.plot.mis, aes(x=Method, y=ARI, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("Misclassification Number of Optimized Neutral Nets and Random Forests") +
theme(legend.position="none")
ggplot(sun.opt.plot.ari, aes(x=Method, y=ARI, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("ARI of Optimized Neutral Nets and Random Forests")+
theme(legend.position="none")
# out.aRul <- predArules(df.raw.forA)
# out.aRul$aRulPoi
# out.aRul$aRulEdi
?apriori
# 2 Variables
df.raw.final <- subset(df.rNA, select = c(Class, Odor, StalkColorBelowRing)) %>% as.data.frame()
df.raw.arul <- subset(df.rNA, select = -c(Odor, StalkColorBelowRing)) %>% as.data.frame()
params <- list(support=0.8,confidence=0.8,minlen=2,maxlen=4)
out.aRul <- predArules(df.raw.arul, fmin = 2, fmax = 4)
params <- list(support=0.05,confidence=0.8,minlen=2,maxlen=4)
out.aRul <- predArules(df.raw.arul, fmin = 2, fmax = 4)
params <- list(support=0.05,confidence=0.9,minlen=2,maxlen=4)
out.aRul <- predArules(df.raw.arul, fmin = 2, fmax = 4)
params <- list(support=0.6,confidence=0.9,minlen=2,maxlen=4)
out.aRul <- predArules(df.raw.arul, fmin = 2, fmax = 4)
params <- list(support=0.03,confidence=0.9,minlen=2,maxlen=4)
out.aRul <- predArules(df.raw.arul, fmin = 2, fmax = 4)
out.Forest <- predForest(df.Final = df.raw.forA,
df.Index.Train = df.train.index, fMtry = 4, fnTree = 350)
importance(out.Forest$ForestMod)
varImpPlot(out.Forest$ForestMod)
?varImpPlot
varImpPlot(out.Forest$ForestMod, main="Random Forest Variable Contribution")
ggplot(sun.opt.plot.mis, aes(x=Method, y=MisclassificationNumber, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("Misclassification Number of Optimized Neutral Nets and Random Forests") +
theme(legend.position="none")
colnames(sun.opt.plot.mis) <- c("rm", "Method", "MisclassificationNumber")
ggplot(sun.opt.plot.mis, aes(x=Method, y=MisclassificationNumber, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("Misclassification Number of Optimized Neutral Nets and Random Forests") +
theme(legend.position="none")
sun.opt.plot.mis %>% summary
sun.opt.plot.ari %>% summary
# importance(out.Forest$ForestMod)
# varImpPlot(out.Forest$ForestMod)
sum.opt %>% summary
sum.opt[,1] %>% median
sum.opt[,2] %>% median
sum.opt[,3] %>% median
sum.opt[,4] %>% median
sum.opt[,1] %>% var
sum.opt[,1] %>% var
sum.opt[,2] %>% var
sum.opt[,3] %>% var
sum.opt[,4] %>% var
sum.opt[,1] %>% var
sum.opt[,2] %>% var
sum.opt[,3] %>% var
sum.opt[,4] %>% var
# ARI Plot
colnames(sum.opt) <- c("Nnet", "Forest", "ForestM", "NnetM")
sun.opt.plot.ari <- melt(sum.opt[,c(1,2)])
colnames(sun.opt.plot.ari) <- c("rm", "Method", "ARI")
sun.opt.plot.ari
ggplot(sun.opt.plot.ari, aes(x=Method, y=ARI, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("ARI of Optimized Neutral Nets and Random Forests")+
theme(legend.position="none")
# Misclassification Number Plot
colnames(sum.opt) <- c("NnetM", "ForestM", "Forest", "Nnet")
sun.opt.plot.mis <- melt(sum.opt[,-c(1,2)])
colnames(sun.opt.plot.mis) <- c("rm", "Method", "MisclassificationNumber")
sun.opt.plot.mis %>% summary
ggplot(sun.opt.plot.mis, aes(x=Method, y=MisclassificationNumber, fill = Method)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("Misclassification Number of Optimized Neutral Nets and Random Forests") +
theme(legend.position="none")
ggplot(sun.opt.plot.ari, aes(x=Method, y=ARI)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("ARI of Optimized Neutral Nets and Random Forests")+
theme(legend.position="none")
ggplot(sun.opt.plot.mis, aes(x=Method, y=MisclassificationNumber)) +
geom_boxplot() +
theme_tufte() + theme(axis.line=element_line()) +
ggtitle("Misclassification Number of Optimized Neutral Nets and Random Forests") +
theme(legend.position="none")
sum.opt[,1] %>% var
sum.opt[,2] %>% var
varImpPlot(out.Forest$ForestMod, main="Random Forest Variable Contribution")
